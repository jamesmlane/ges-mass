{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - make_ksf.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges_mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Create the KSF. First create DF models of the halo, then sample kinematics \n",
    "on a sparse grid. Finally map onto the effective selection function grid using \n",
    "spline interpolation.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np, sys, os, copy, warnings, operator, time\n",
    "from astropy import units as apu\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import dill as pickle\n",
    "\n",
    "## galpy\n",
    "from galpy import orbit\n",
    "from galpy import potential\n",
    "from galpy import actionAngle as aA\n",
    "from galpy import df\n",
    "from galpy.util import multi as galpy_multi\n",
    "\n",
    "## scipy\n",
    "from scipy import interpolate\n",
    "\n",
    "## Project-specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "from ges_mass import potential as ppotential\n",
    "from ges_mass import util as putil\n",
    "from ges_mass import ssf as pssf\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Keywords, Pathing, Loading, Data Preparation\n",
    "Note may need to manually set DF_VERSION and KSF_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/keywords_pathing_loading_data_prep.py\n",
    "## Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['BASE_DIR','APOGEE_DR','APOGEE_RESULTS_VERS','GAIA_DR','NDMOD',\n",
    "            'DMOD_MIN','DMOD_MAX','LOGG_MIN','LOGG_MAX','FEH_MIN','FEH_MAX',\n",
    "            'FEH_MIN_GSE','FEH_MAX_GSE','DF_VERSION','KSF_VERSION','NPROCS',\n",
    "            'RO','VO','ZO']\n",
    "base_dir,apogee_dr,apogee_results_vers,gaia_dr,ndmod,dmod_min,dmod_max,\\\n",
    "    logg_min,logg_max,feh_min,feh_max,feh_min_gse,feh_max_gse,df_version,\\\n",
    "    ksf_version,nprocs,ro,vo,zo = putil.parse_config_dict(cdict,keywords)\n",
    "logg_range = [logg_min,logg_max]\n",
    "feh_range = [feh_min,feh_max]\n",
    "feh_range_gse = [feh_min_gse,feh_max_gse]\n",
    "feh_range_all = [feh_min,feh_max_gse]\n",
    "# feh_range_fit = copy.deepcopy( # Need to choose here\n",
    "\n",
    "# # Manually override df and ksf information if necessary\n",
    "# df_version = 'v1.1_alpha35_rc30'\n",
    "# ksf_version = 'v1_beta_03_09_5050mix'\n",
    "df_version = 'v4_lb_powerspher_hb_hernquist'\n",
    "ksf_version = 'v4.01_beta_03_6e8_08_1.5e8'\n",
    "\n",
    "## Pathing\n",
    "fit_paths = putil.prepare_paths(base_dir,apogee_dr,apogee_results_vers,gaia_dr,\n",
    "                                df_version,ksf_version)\n",
    "data_dir,version_dir,ga_dir,gap_dir,df_dir,ksf_dir,fit_dir = fit_paths\n",
    "\n",
    "## Filenames\n",
    "fit_filenames = putil.prepare_filenames(ga_dir,gap_dir,feh_range_gse)\n",
    "apogee_SF_filename,apogee_effSF_filename,apogee_effSF_mask_filename,\\\n",
    "    iso_grid_filename,clean_kinematics_filename = fit_filenames\n",
    "\n",
    "## File loading and data preparation\n",
    "fit_stuff,other_stuff = putil.prepare_fitting(fit_filenames,\n",
    "    [ndmod,dmod_min,dmod_max],ro,zo,return_other=True)\n",
    "apogee_effSF_mask,dmap,iso_grid,jkmins,dmods,ds,effsel_grid,apof,\\\n",
    "    allstar_nomask,orbs_nomask = fit_stuff\n",
    "Rgrid,phigrid,zgrid = effsel_grid\n",
    "# apogee_SF,apogee_effSF_grid_inclArea,apogee_effSF_grid_inclArea_Jac = other_stuff\n",
    "\n",
    "# ## Load the APOGEE field information, can also similarly load \n",
    "# ## '...apogee_field_glons.npy', '...apogee_field_glats.npy', \n",
    "# ## '...apogee_field_location_ids.npy'\n",
    "apogee_fields = np.load(ga_dir+'apogee_fields.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra files and parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames\n",
    "fig_dir = './fig/'\n",
    "df_filename = df_dir+'dfs.pkl'\n",
    "kinematics_filename = df_dir+'kinematics_ksf_correction.pkl'\n",
    "allstar_filename = ga_dir+'apogee_allstar.npy'\n",
    "apogee_stat_indx_filename = ga_dir+'apogee_statIndx.npy'\n",
    "gaia_data_filename = ga_dir+'gaia_data.npy'\n",
    "gaia_apogee_matches_filename = ga_dir+'gaia_apogee_matches.npy'\n",
    "\n",
    "# Forcing\n",
    "force_dfs = True # New DFs\n",
    "force_kinematics = True # New orbit samples\n",
    "force_splines = True # New splines of completeness and purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make potential and DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpolated Milky Way potential\n",
    "rmin = 1/ro # 1 kpc\n",
    "rmax = 80/ro # 80 kpc\n",
    "rmin_interp = rmin/2.\n",
    "rmax_interp = rmax*2.\n",
    "ngrid = 1601\n",
    "interpot = ppotential.make_interpolated_mwpot(mwpot='MWPotential2014',\n",
    "    rmin=rmin_interp, rmax=rmax_interp, ngrid=ngrid, ro=ro, vo=vo, \n",
    "    match_type='mass')\n",
    "mwpot = potential.MWPotential2014\n",
    "potential.turn_physical_on(interpot,ro=ro,vo=vo)\n",
    "potential.turn_physical_on(mwpot,ro=ro,vo=vo)\n",
    "phi0 = potential.evaluatePotentials(mwpot,1e12,0).value\n",
    "\n",
    "## Stellar halo density potential\n",
    "\n",
    "# # Lane+ 2022 model \n",
    "# alpha = 3.5 # halo density inner power law slope\n",
    "# rc = 30*apu.kpc\n",
    "# denspot = potential.PowerSphericalPotentialwCutoff(amp=1., r1=1.,\n",
    "#     alpha=alpha, rc=rc, ro=ro, vo=vo)\n",
    "# potential.turn_physical_on(denspot,ro=ro,vo=vo)\n",
    "\n",
    "# Or make a denspot each for lowbeta and highbeta + give normalizing information\n",
    "alpha_lb = 2.5\n",
    "denspot_lb = potential.PowerSphericalPotential(amp=1., r1=1., alpha=alpha_lb,\n",
    "    ro=ro, vo=vo)\n",
    "potential.turn_physical_on(denspot_lb,ro=ro,vo=vo)\n",
    "alpha_hb = 1.\n",
    "beta_hb = 4.\n",
    "a_hb = 20.*apu.kpc\n",
    "denspot_hb = potential.TwoPowerSphericalPotential(amp=1., alpha=alpha_hb,\n",
    "    beta=beta_hb, a=a_hb, ro=ro, vo=vo)\n",
    "potential.turn_physical_on(denspot_hb,ro=ro,vo=vo)\n",
    "\n",
    "# Give some way to normalize the two density profiles if they're not the same\n",
    "denspot_norm_rmin = 2*apu.kpc\n",
    "denspot_norm_rmax = 55*apu.kpc\n",
    "mass_denspot_lb = 6e8*apu.M_sun\n",
    "mass_denspot_hb = 1.5e8*apu.M_sun\n",
    "denspot_lb = ppotential.normalize_potential_from_mass(denspot_lb,\n",
    "    mass_denspot_lb,denspot_norm_rmin,denspot_norm_rmax)\n",
    "denspot_hb = ppotential.normalize_potential_from_mass(denspot_hb,\n",
    "    mass_denspot_hb,denspot_norm_rmin,denspot_norm_rmax)\n",
    "assert np.isclose((potential.mass(denspot_lb,denspot_norm_rmax)-\\\n",
    "    potential.mass(denspot_lb,denspot_norm_rmin)).value,\n",
    "    mass_denspot_lb.value),'mass is not close to the target value'\n",
    "assert np.isclose((potential.mass(denspot_hb,denspot_norm_rmax)-\\\n",
    "    potential.mass(denspot_hb,denspot_norm_rmin)).value,\n",
    "    mass_denspot_hb.value),'mass is not close to the target value'\n",
    "    \n",
    "\n",
    "# Fill in some checks on denspot here for consistency\n",
    "if 'alpha35_rc30' in df_version:\n",
    "    assert alpha==3.5\n",
    "    assert rc.to(apu.kpc).value == 30\n",
    "if df_version == 'v2_lb_ps_hb_tp':\n",
    "    assert alpha_lb==2.5\n",
    "    assert alpha_hb==1.\n",
    "    assert beta_hb==4 or beta_hb==4.5\n",
    "    assert a_hb.to(apu.kpc).value==20.\n",
    "if df_version == 'v3_lb_ps_hb_tp':\n",
    "    assert alpha_lb==2.5\n",
    "    assert alpha_hb==1.\n",
    "    assert beta_hb==4 or beta_hb==4.5\n",
    "    assert a_hb.to(apu.kpc).value==20.\n",
    "# if df_verison == 'v3...':\n",
    "#    assert ...\n",
    "#    assert ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DFs\n",
    "# betas = [0.3,0.4,0.8,0.9]\n",
    "betas = [0.3,0.8]\n",
    "# denspots = [denspot]*len(betas)\n",
    "denspots = [denspot_lb,denspot_hb]\n",
    "n_dfs = len(betas)\n",
    "n_samples = 1000 # samples in each distance modulus bin\n",
    "\n",
    "if force_dfs or not os.path.exists(df_filename):\n",
    "    dfs = []\n",
    "    for i in range(len(betas)):\n",
    "            # DF initialization is noisy\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                dfm = df.constantbetadf(pot=interpot, denspot=denspots[i], \n",
    "                                        ro=ro, vo=vo, beta=betas[i], rmax=rmax)\n",
    "                # Dummy samping to initialize\n",
    "                _ = dfm.sample(R=np.ones(n_samples)*ro*apu.kpc, \n",
    "                    phi=np.zeros(n_samples), z=np.zeros(n_samples), rmin=rmin)\n",
    "                dfs.append(dfm)\n",
    "    with open(df_filename,'wb') as f:\n",
    "        pickle.dump(dfs,f)\n",
    "else:\n",
    "    with open(df_filename,'rb') as f:\n",
    "        print('Loading DFs from '+df_filename)\n",
    "        dfs = pickle.load(f)\n",
    "    check_params = ['_beta','_rmin_sampling','_rmax','_pot','_denspot',\n",
    "                    '_denspot.alpha','_denspot.rc','_denspot.beta','_denspot.a']\n",
    "    for i in range(len(dfs)):\n",
    "        print('\\ndf['+str(i)+'] properties')\n",
    "        for j in range(len(check_params)):\n",
    "            try:\n",
    "                prop = operator.attrgetter(check_params[j])(dfs[i])\n",
    "                print(check_params[j]+': '+str(prop))\n",
    "            except AttributeError:\n",
    "                print(check_params[j]+': N/A')\n",
    "        assert dfs[i]._beta == betas[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaia and APOGEE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load APOGEE data\n",
    "print('APOGEE data release is: '+apogee_dr+', and results version is: '+apogee_results_vers)\n",
    "print('Loading APOGEE from '+allstar_filename)\n",
    "allstar = np.load(allstar_filename)\n",
    "print(str(len(allstar))+' stars in total sample.')\n",
    "\n",
    "# load APOGEE statistical sample index\n",
    "print('\\nLoading APOGEE DR16 statistical sample from '+apogee_stat_indx_filename)\n",
    "apogee_stat_indx = np.load(apogee_stat_indx_filename)\n",
    "print(str(np.sum(apogee_stat_indx))+' stars in statistical sample.')\n",
    "\n",
    "# Gaia data and Gaia-APOGEE match index\n",
    "print('\\nGaia data release is: '+gaia_dr)\n",
    "print('Loading Gaia catalog from '+gaia_data_filename)\n",
    "gaia_data = np.load(gaia_data_filename, allow_pickle=True)\n",
    "print('Loading Gaia-APOGEE matches from '+gaia_apogee_matches_filename)\n",
    "gaia_apogee_matches_indx = np.load(gaia_apogee_matches_filename)\n",
    "\n",
    "# Apply the statistical sample index and Gaia-APOGEE matching index\n",
    "allstar_gaia = allstar[apogee_stat_indx][gaia_apogee_matches_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have defined 6D kinematics for eccentricities\n",
    "input_mask = np.isfinite(gaia_data['RA']) &\\\n",
    "             np.isfinite(gaia_data['DEC']) &\\\n",
    "             np.isfinite(gaia_data['pmra']) &\\\n",
    "             np.isfinite(gaia_data['pmdec']) &\\\n",
    "             np.isfinite(allstar_gaia['weighted_dist']) &\\\n",
    "             np.isfinite(allstar_gaia['VHELIO_AVG'])\n",
    "\n",
    "allstar_input = allstar_gaia[input_mask]\n",
    "gaia_input = gaia_data[input_mask]\n",
    "\n",
    "# Make coordinate array -> orbits\n",
    "vxvv = np.array([gaia_input['RA'],\n",
    "                 gaia_input['DEC'],\n",
    "                 allstar_input['weighted_dist']/1000,\n",
    "                 gaia_input['pmra'],\n",
    "                 gaia_input['pmdec'],\n",
    "                 allstar_input['VHELIO_AVG']\n",
    "                 ]).T\n",
    "orbs_gaia_apo = orbit.Orbit(vxvv=vxvv, radec=True, ro=ro, vo=vo, zo=zo)\n",
    "\n",
    "# Trim the size of gaia_input and allstar_input by only keeping some fields\n",
    "gaia_input,allstar_input = putil.trim_gaia_allstar_input(gaia_input,\n",
    "                                                         allstar_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the locations of the APOGEE SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual pointing information\n",
    "ls_pointing = np.load(ga_dir+'apogee_field_glons.npy')\n",
    "bs_pointing = np.load(ga_dir+'apogee_field_glats.npy')\n",
    "locids_pointing = np.load(ga_dir+'apogee_field_location_ids.npy')\n",
    "n_pointing = len(locids_pointing)\n",
    "\n",
    "# Get individual distance information\n",
    "n_ds = 21\n",
    "dmods_individual = np.linspace(dmod_min,dmod_max,num=n_ds) # About 1 to 50 kpc\n",
    "ds_individual = 10**(dmods_individual/5-2)\n",
    "print('Distances [kpc] along each LOS where KSF will be calculated:')\n",
    "print(ds_individual)\n",
    "\n",
    "# Tile this information to create a grid of pointings x distances\n",
    "ds_locs = np.tile(ds_individual,reps=len(ls_pointing)) # repeat array one after the other\n",
    "bs_locs = np.repeat(bs_pointing,repeats=len(ds_individual)) # repeat each element\n",
    "ls_locs = np.repeat(ls_pointing,repeats=len(ds_individual))\n",
    "fs_locs = np.repeat(locids_pointing,repeats=len(ds_individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the locations of APOGEE pointings\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ls_plot = copy.deepcopy(ls_pointing)\n",
    "ls_plot[ ls_plot>180  ] = ls_plot[ ls_plot>180 ]-360\n",
    "pts = ax.scatter( ls_plot, bs_pointing, c='Black', s=4, zorder=2 )\n",
    "ax.set_xlabel('$\\ell$ [deg]')\n",
    "ax.set_ylabel('$b$ [deg]')\n",
    "ax.set_xlim(185,-185)\n",
    "ax.set_ylim(-95,95)\n",
    "bulge_patch = mpl.patches.Rectangle(xy=(-20,-20),width=40,height=40,\n",
    "    edgecolor='Black',facecolor='None', zorder=3)\n",
    "ax.add_artist(bulge_patch)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address weird galpy error\n",
    "ls_locs[0:n_ds] = 90.001 \n",
    "ls_locs[1050] = 90.001\n",
    "ls_locs[1060] = 90.001\n",
    "\n",
    "# Make orbits for each individual location in the pointing x distance grid\n",
    "vxvvs_locs = np.array([ls_locs,bs_locs,ds_locs,np.zeros_like(ds_locs),\n",
    "                       np.zeros_like(ds_locs),np.zeros_like(ds_locs)]).T\n",
    "# Orbits to do coordinate tranformation\n",
    "orbs_locs = orbit.Orbit(vxvvs_locs,lb=True,ro=ro,vo=vo,zo=zo)\n",
    "n_locs = len(orbs_locs)\n",
    "\n",
    "# Undo fudge for galpy error\n",
    "ls_grid = np.repeat(ls_pointing,repeats=len(ds_individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matches into the gaia and apogee orbits\n",
    "indx,sep2d,dist3d = putil.find_orbit_nearest_neighbor(orbs_locs,orbs_gaia_apo,ro=ro, vo=vo)\n",
    "print('Max 2D angular separation')\n",
    "print(sep2d.max())\n",
    "print('\\nMax 3D distance')\n",
    "print(dist3d.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_beta = True\n",
    "beta_filename = ksf_dir+'betas_ksf.pkl'\n",
    "if not os.path.exists(kinematics_filename) or force_kinematics:\n",
    "    aAS = aA.actionAngleStaeckel(pot=mwpot, delta=0.4, ro=ro, vo=vo, zo=zo, c=True)\n",
    "    do_perturb_orbs = False\n",
    "\n",
    "    # Calculate deltas only once for each location\n",
    "    print('Calculating Staeckel deltas...')\n",
    "    delta = aA.estimateDeltaStaeckel(mwpot, orbs_locs.R(), orbs_locs.z(), \n",
    "                                     no_median=True)\n",
    "    if isinstance(delta,apu.quantity.Quantity):\n",
    "        delta = delta.to(apu.kpc).value/ro\n",
    "    \n",
    "    orbs = []\n",
    "    eELzs = np.zeros((len(dfs),n_locs,3,n_samples))\n",
    "    actions = np.zeros((len(dfs),n_locs,3,n_samples))\n",
    "\n",
    "    # Timing\n",
    "    t1 = time.time()\n",
    "    for i in range(len(dfs)):\n",
    "        print('Doing beta='+str(dfs[i]._beta))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            results = pssf.calc_kinematics_parallel(nprocs, dfs[i], n_samples,\n",
    "                orbs_locs, do_perturb_orbs, gaia_input[indx], \n",
    "                allstar_input[indx], delta, aAS, mwpot, ro, vo, zo)\n",
    "        these_orbs,these_eELzs,these_actions = results.T\n",
    "        orbs.append( list(these_orbs) )\n",
    "        eELzs[i] = np.stack(these_eELzs)\n",
    "        actions[i] = np.stack(these_actions)\n",
    "    if calculate_beta:\n",
    "        print('Calculating beta...')\n",
    "        orbs_betas = pssf.calc_beta(orbs)\n",
    "        np.save(beta_filename,orbs_betas)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('Took '+str(round(t2-t1))+'s')\n",
    "    print('Saving KSF kinematics to '+kinematics_filename)\n",
    "    with open(kinematics_filename,'wb') as f:\n",
    "        pickle.dump([delta,eELzs,actions,orbs],f)\n",
    "else:\n",
    "    print('Loading KSF kinematics from '+kinematics_filename)\n",
    "    with open(kinematics_filename,'rb') as f:\n",
    "        delta,eELzs,actions,orbs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Purity and Completeness & Fit Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package the kinematics properly according to the beta's we're interested in\n",
    "# Then validate that choice\n",
    "\n",
    "low_beta = 0.3\n",
    "high_beta = 0.8\n",
    "\n",
    "low_beta_indx = np.where(np.array(betas)==low_beta)[0][0]\n",
    "high_beta_indx = np.where(np.array(betas)==high_beta)[0][0]\n",
    "\n",
    "orbs_spline = [orbs[low_beta_indx],orbs[high_beta_indx]]\n",
    "eELzs_spline = [eELzs[low_beta_indx],eELzs[high_beta_indx]]\n",
    "actions_spline = [actions[low_beta_indx],actions[high_beta_indx]]\n",
    "mixture_arr = np.array([1.,1.]) # Equal amounts of low and high beta\n",
    "\n",
    "# Setting denspots to None forces the purity to be calculated with the \n",
    "no_denspot_ksf_versions = ['v1_beta_03_08_5050mix','v1_beta_03_09_5050mix',]\n",
    "if ksf_version in no_denspot_ksf_versions:\n",
    "    denspots_spline = [None,None]\n",
    "else:\n",
    "    denspots_spline = [denspots[low_beta_indx],denspots[high_beta_indx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test to make sure that ksf version matches beta choices\n",
    "# if ksf_version == 'v1_beta_03_08_5050mix':\n",
    "#     assert low_beta == 0.3\n",
    "#     assert high_beta == 0.8\n",
    "#     assert np.all(mixture_arr == np.array([1.,1.]))\n",
    "# if ksf_version == 'v1_beta_03_09_5050mix':\n",
    "#     assert low_beta == 0.3\n",
    "#     assert high_beta == 0.9\n",
    "#     assert np.all(mixture_arr == np.array([1.,1.]))\n",
    "# if ksf_version == 'v2_beta_03_6e8_09_1.5e8':\n",
    "#     assert low_beta == 0.3\n",
    "#     assert high_beta == 0.9\n",
    "#     assert isinstance(denspots[0],potential.Potential)\n",
    "#     assert isinstance(denspots[1],potential.Potential)\n",
    "# if ksf_version == 'v1_beta_03_6e8_09_1.5e8':\n",
    "#     assert low_beta == 0.3\n",
    "#     assert high_beta == 0.9\n",
    "#     assert isinstance(denspots[0],potential.Potential)\n",
    "#     assert isinstance(denspots[1],potential.Potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection ellipse dictionary\n",
    "\n",
    "halo_selection_survey_dict = putil.lane2022_kinematic_selections(version='current')\n",
    "\n",
    "# # These are old selections from an draft version of Lane+ 2021\n",
    "# halo_selection_survey_dict = {'vRvT':   [ ['ellipse', [290,0], [110,35]], \n",
    "#                                           ['ellipse', [-290,0], [110,35]] ],\n",
    "#                               'Toomre': [ ['ellipse', [0,300], [35,120]], ],\n",
    "#                               'ELz':    [ ['ellipse', [0,-1], [300,0.5]], ],\n",
    "#                               'JRLz':   [ ['ellipse', [0,45], [300,20]], ],\n",
    "#                               'eLz':    [ ['ellipse', [0,1], [500,0.025]], ],\n",
    "#                               'AD':     [ ['ellipse', [0,-1], [0.08,0.3]], ]\n",
    "#                               }\n",
    "\n",
    "# # These are the new selections from Lane+ 2021\n",
    "# halo_selection_survey_dict = {'vRvT':   [ ['ellipse', [280,0], [100,40]], \n",
    "#                                           ['ellipse', [-280,0], [100,40]] ],\n",
    "#                               'Toomre': [ ['ellipse', [0,280], [35,100]], ],\n",
    "#                               'ELz':    [ ['ellipse', [0,-1], [300,0.5]], ],\n",
    "#                               'JRLz':   [ ['ellipse', [0,45], [300,15]], ],\n",
    "#                               'eLz':    [ ['ellipse', [0,1], [500,0.05]], ],\n",
    "#                               'AD':     [ ['ellipse', [0,-1], [0.08,0.3]], ]\n",
    "#                               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over different spaces and create the splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_spaces = [['AD',],\n",
    "                ['eLz',],\n",
    "                ['JRLz'],\n",
    "               ]\n",
    "for i in range(len(selec_spaces)):\n",
    "    pssf.make_completeness_purity_splines(selec_spaces[i], orbs_spline, \n",
    "        eELzs_spline, actions_spline, mixture_arr, denspots_spline, \n",
    "        halo_selection_survey_dict, phi0, \n",
    "        [ls_pointing,bs_pointing,locids_pointing], ds_individual, fs_locs, \n",
    "        ksf_dir, fig_dir, force_splines=True, force_cp=True, spline_type='both', \n",
    "        make_spline_plots=False, n_spline_plots=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map splines onto the effective selection function grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(selec_spaces)):\n",
    "    keffSF_grid = pssf.create_kSF_grid(selec_spaces[i], apogee_fields, ds, \n",
    "        ksf_dir, spline_type='both', make_purity_grid=True)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "0.22.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c09f9892750024efe5c64805177155c0b3b90c2cacf15a9f18cf8d6a11608de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
