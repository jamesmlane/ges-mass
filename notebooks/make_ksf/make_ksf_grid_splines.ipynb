{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - make_ksf_grid_correction_parallel.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges_mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Parallelize the creation of the KSF grid\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np, sys, os, copy, warnings, operator, time, multiprocessing\n",
    "from astropy import units as apu\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import dill as pickle\n",
    "import tqdm\n",
    "\n",
    "## galpy\n",
    "from galpy import orbit\n",
    "from galpy import potential\n",
    "from galpy import actionAngle as aA\n",
    "from galpy import df\n",
    "from galpy.util import multi as galpy_multi\n",
    "\n",
    "## scipy\n",
    "from scipy import interpolate\n",
    "\n",
    "## Project-specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "from ges_mass import potential as ppotential\n",
    "from ges_mass import plot as pplot\n",
    "from ges_mass import util as putil\n",
    "from ges_mass import ssf as pssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook setup\n",
    "%matplotlib inline\n",
    "plt.style.use('jl_notebook') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "ncores = int(multiprocessing.cpu_count()//2) # Include in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','APOGEE_DR','APOGEE_RESULTS_VERS','GAIA_DR','RO','VO','ZO']\n",
    "data_dir_base,apogee_dr,apogee_results_vers,gaia_dr,ro,vo,zo\\\n",
    "    = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# Pathing\n",
    "data_dir = data_dir_base+'gaia_apogee/'\n",
    "out_dir = data_dir_base+'ksf/'\n",
    "fig_dir = './fig/'\n",
    "gaia_apogee_dir = 'apogee_'+apogee_dr+'_'+apogee_results_vers+'_gaia_'+gaia_dr+'/'\n",
    "os.makedirs(out_dir+gaia_apogee_dir,exist_ok=True)\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "\n",
    "# Filenames\n",
    "df_filename = out_dir+gaia_apogee_dir+'dfs.pkl'\n",
    "allstar_filename = data_dir+gaia_apogee_dir+'apogee_allstar.npy'\n",
    "apogee_stat_indx_filename = data_dir+gaia_apogee_dir+'apogee_statIndx.npy'\n",
    "gaia_data_filename = data_dir+gaia_apogee_dir+'gaia_data.npy'\n",
    "gaia_apogee_matches_filename = data_dir+gaia_apogee_dir+'gaia_apogee_matches.npy'\n",
    "kinematics_filename = out_dir+gaia_apogee_dir+'kinematics_ksf_correction.pkl'\n",
    "\n",
    "# Forcing\n",
    "force_dfs = False # New DFs\n",
    "force_kinematics = False # New orbit samples\n",
    "force_splines = False # New splines of completeness and purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make potential and DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolated Milky Way potential\n",
    "rmin = 1/ro # 1 kpc\n",
    "rmax = 60/ro # 60 kpc\n",
    "rmin_interp = rmin/2.\n",
    "rmax_interp = rmax*2.\n",
    "ngrid = 1601\n",
    "interpot = ppotential.make_interpolated_mwpot(mwpot='MWPotential2014',\n",
    "    rmin=rmin_interp, rmax=rmax_interp, ngrid=ngrid, ro=ro, vo=vo, \n",
    "    match_type='mass')\n",
    "mwpot = potential.MWPotential2014\n",
    "potential.turn_physical_on(interpot,ro=ro,vo=vo)\n",
    "potential.turn_physical_on(mwpot,ro=ro,vo=vo)\n",
    "phi0 = potential.evaluatePotentials(mwpot,1e12,0).value\n",
    "\n",
    "# Stellar halo density potential\n",
    "alpha = 3.5 # halo density inner power law slope\n",
    "rc = 30*apu.kpc\n",
    "denspot = potential.PowerSphericalPotentialwCutoff(amp=1., r1=1.,\n",
    "    alpha=alpha, rc=rc, ro=ro, vo=vo)\n",
    "potential.turn_physical_on(denspot,ro=ro,vo=vo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DFs\n",
    "betas = [0.5,0.9]\n",
    "n_dfs = len(betas)\n",
    "n_samples = 800 # samples in each distance modulus bin\n",
    "\n",
    "if force_dfs or not os.path.exists(df_filename):\n",
    "    dfs = []\n",
    "    for i in range(len(betas)):\n",
    "            # DF initialization is noisy\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                dfm = df.constantbetadf(pot=interpot, denspot=denspot, ro=ro, vo=vo, \n",
    "                    beta=betas[i], rmax=rmax)\n",
    "                # Dummy samping to initialize\n",
    "                _ = dfm.sample(R=np.ones(n_samples)*ro*apu.kpc, \n",
    "                    phi=np.zeros(n_samples), z=np.zeros(n_samples), rmin=rmin)\n",
    "                dfs.append(dfm)\n",
    "            ##wi\n",
    "        ###i\n",
    "    with open(df_filename,'wb') as f:\n",
    "        pickle.dump(dfs,f)\n",
    "    ##wi\n",
    "else:\n",
    "    with open(df_filename,'rb') as f:\n",
    "        print('Loading DFs from '+df_filename)\n",
    "        dfs = pickle.load(f)\n",
    "    ##wi\n",
    "    check_params = ['_beta','_rmin_sampling','_rmax','_pot','_denspot','_denspot.alpha','_denspot.rc']\n",
    "    for i in range(len(dfs)):\n",
    "        print('\\ndf['+str(i)+'] properties')\n",
    "        for j in range(len(check_params)):\n",
    "            print(check_params[j]+': '+str(operator.attrgetter(check_params[j])(dfs[i])))\n",
    "        ###j\n",
    "    ###i\n",
    "##ie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaia and APOGEE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load APOGEE data\n",
    "print('APOGEE data release is: '+apogee_dr+', and results version is: '+apogee_results_vers)\n",
    "print('Loading APOGEE from '+allstar_filename)\n",
    "allstar = np.load(allstar_filename)\n",
    "print(str(len(allstar))+' stars in total sample.')\n",
    "\n",
    "# load APOGEE statistical sample index\n",
    "print('\\nLoading APOGEE DR16 statistical sample from '+apogee_stat_indx_filename)\n",
    "apogee_stat_indx = np.load(apogee_stat_indx_filename)\n",
    "print(str(np.sum(apogee_stat_indx))+' stars in statistical sample.')\n",
    "\n",
    "# Gaia data and Gaia-APOGEE match index\n",
    "print('\\nGaia data release is: '+gaia_dr)\n",
    "print('Loading Gaia catalog from '+gaia_data_filename)\n",
    "gaia_data = np.load(gaia_data_filename, allow_pickle=True)\n",
    "print('Loading Gaia-APOGEE matches from '+gaia_apogee_matches_filename)\n",
    "gaia_apogee_matches_indx = np.load(gaia_apogee_matches_filename)\n",
    "\n",
    "# Apply the statistical sample index and Gaia-APOGEE matching index\n",
    "allstar_gaia = allstar[apogee_stat_indx][gaia_apogee_matches_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have defined 6D kinematics for eccentricities\n",
    "input_mask = np.isfinite(gaia_data['RA']) &\\\n",
    "             np.isfinite(gaia_data['DEC']) &\\\n",
    "             np.isfinite(gaia_data['pmra']) &\\\n",
    "             np.isfinite(gaia_data['pmdec']) &\\\n",
    "             np.isfinite(allstar_gaia['weighted_dist']) &\\\n",
    "             np.isfinite(allstar_gaia['VHELIO_AVG'])\n",
    "\n",
    "allstar_input = allstar_gaia[input_mask]\n",
    "gaia_input = gaia_data[input_mask]\n",
    "\n",
    "# Make coordinate array -> orbits\n",
    "vxvv = np.array([gaia_input['RA'],\n",
    "                 gaia_input['DEC'],\n",
    "                 allstar_input['weighted_dist']/1000,\n",
    "                 gaia_input['pmra'],\n",
    "                 gaia_input['pmdec'],\n",
    "                 allstar_input['VHELIO_AVG']\n",
    "                 ]).T\n",
    "orbs_gaia_apo = orbit.Orbit(vxvv=vxvv, radec=True, ro=ro, vo=vo, zo=zo)\n",
    "\n",
    "# Trim the size of gaia_input and allstar_input by only keeping some fields\n",
    "gaia_input,allstar_input = putil.trim_gaia_allstar_input(gaia_input,\n",
    "                                                         allstar_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the locations of the APOGEE SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual pointing information\n",
    "ls_pointing = np.load(data_dir+gaia_apogee_dir+'apogee_field_glons.npy')\n",
    "bs_pointing = np.load(data_dir+gaia_apogee_dir+'apogee_field_glats.npy')\n",
    "locids_pointing = np.load(data_dir+gaia_apogee_dir+'apogee_field_location_ids.npy')\n",
    "n_pointing = len(locids_pointing)\n",
    "\n",
    "# Get individual distance information\n",
    "n_ds = 14\n",
    "dmod_lim = [7,19]\n",
    "dmods = np.linspace(dmod_lim[0],dmod_lim[1],num=n_ds) # About 1 to 50 kpc\n",
    "ds_individual = 10**(dmods/5-2)\n",
    "print('Distances [kpc]:')\n",
    "print(ds_individual)\n",
    "\n",
    "# Tile this information to create a grid of pointings x distances\n",
    "ds = np.tile(ds_individual,reps=len(ls_pointing)) # repeat array one after the other\n",
    "bs = np.repeat(bs_pointing,repeats=len(ds_individual)) # repeat each element\n",
    "ls = np.repeat(ls_pointing,repeats=len(ds_individual))\n",
    "fs = np.repeat(locids_pointing,repeats=len(ds_individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the locations of APOGEE pointings\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ls_plot = copy.deepcopy(ls_pointing)\n",
    "ls_plot[ ls_plot>180  ] = ls_plot[ ls_plot>180 ]-360\n",
    "pts = ax.scatter( ls_plot, bs_pointing, c='Black', s=4, zorder=2 )\n",
    "ax.set_xlabel('$\\ell$ [deg]')\n",
    "ax.set_ylabel('$b$ [deg]')\n",
    "ax.set_xlim(185,-185)\n",
    "ax.set_ylim(-95,95)\n",
    "bulge_patch = mpl.patches.Rectangle(xy=(-20,-20),width=40,height=40,\n",
    "    edgecolor='Black',facecolor='None', zorder=3)\n",
    "ax.add_artist(bulge_patch)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address weird galpy error\n",
    "ls[0:n_ds] = 90.001 \n",
    "ls[1050] = 90.001\n",
    "ls[1060] = 90.001\n",
    "\n",
    "# Make orbits for each individual location in the pointing x distance grid\n",
    "vxvvs = np.array([ls,bs,ds,np.zeros_like(ds),np.zeros_like(ds),np.zeros_like(ds)]).T\n",
    "orbs_locs = orbit.Orbit(vxvvs,lb=True,ro=ro,vo=vo,zo=zo) # Orbits to do coordinate tranformation\n",
    "n_locs = len(orbs_locs)\n",
    "\n",
    "ls = np.repeat(ls_pointing,repeats=len(ds_individual)) # Undo fudge for galpy error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matches into the gaia and apogee orbits\n",
    "indx,sep2d,dist3d = putil.find_orbit_nearest_neighbor(orbs_locs,orbs_gaia_apo,ro=ro, vo=vo)\n",
    "print('Max 2D angular separation')\n",
    "print(sep2d.max())\n",
    "print('\\nMax 3D distance')\n",
    "print(dist3d.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncores_temp = 4\n",
    "\n",
    "if not os.path.exists(kinematics_filename) or force_kinematics:\n",
    "    aAS = aA.actionAngleStaeckel(pot=mwpot, delta=0.4, ro=ro, vo=vo, zo=zo, c=True)\n",
    "    do_perturb_orbs = True\n",
    "\n",
    "    # Calculate deltas only once for each location\n",
    "    print('Calculating Staeckel deltas...')\n",
    "    deltas = aA.estimateDeltaStaeckel(mwpot, orbs_locs.R(), \n",
    "                                      orbs_locs.z(), no_median=True)\n",
    "    \n",
    "    orbs = []\n",
    "    eELzs = np.zeros((len(dfs),n_locs,3,n_samples))\n",
    "    actions = np.zeros((len(dfs),n_locs,3,n_samples))\n",
    "\n",
    "    # Timing\n",
    "    t1 = time.time()\n",
    "    for i in range(len(dfs)):\n",
    "        print('Doing beta='+str(dfs[i]._beta))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            results = calc_kinematics_parallel(ncores_temp, dfs[i], n_samples,\n",
    "                orbs_locs, do_perturb_orbs,gaia_input[indx], \n",
    "                allstar_input[indx], deltas, aAS, ro, vo, zo)\n",
    "        ##wi\n",
    "        these_orbs,these_eELzs,these_actions = results.T\n",
    "        orbs.append( list(these_orbs) )\n",
    "        eELzs[i] = np.stack(these_eELzs)\n",
    "        actions[i] = np.stack(these_actions)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('Took '+str(round(t2-t1))+'s')\n",
    "    print('Saving KSF kinematics to '+kinematics_filename)\n",
    "    with open(kinematics_filename,'wb') as f:\n",
    "        pickle.dump([deltas,eELzs,actions,orbs],f)\n",
    "    ##wi\n",
    "else:\n",
    "    print('Loading KSF kinematics from '+kinematics_filename)\n",
    "    with open(kinematics_filename,'rb') as f:\n",
    "        deltas,eELzs,actions,orbs = pickle.load(f)\n",
    "    ##wi\n",
    "##ie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Purity and Completeness & Fit Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection ellipse dictionary\n",
    "halo_selection_survey_dict = {'vRvT':   [ ['ellipse', [290,0], [110,35]], \n",
    "                                          ['ellipse', [-290,0], [110,35]] ],\n",
    "                              'Toomre': [ ['ellipse', [0,300], [35,120]], ],\n",
    "                              'ELz':    [ ['ellipse', [0,-1], [300,0.5]], ],\n",
    "                              'JRLz':   [ ['ellipse', [0,45], [300,20]], ],\n",
    "                              'eLz':    [ ['ellipse', [0,1], [500,0.025]], ],\n",
    "                              'AD':     [ ['ellipse', [0,-1], [0.08,0.3]], ]\n",
    "                              }\n",
    "\n",
    "# Plotting keywords\n",
    "make_spline_plots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over different spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_spaces = [['AD',],\n",
    "                ['eLz',],\n",
    "                ['JRLz'],\n",
    "                ['AD','eLz'],\n",
    "                ['AD','JRLz'],\n",
    "                ['eLz','JRLz'],\n",
    "               ]\n",
    "for i in range(len(selec_spaces)):\n",
    "    pssf.make_completeness_purity_splines(selec_spaces[i], orbs, eELzs, actions, \n",
    "        halo_selection_survey_dict, phi0,\n",
    "        [ls_pointing,bs_pointing,locids_pointing], ds_individual, fs, out_dir, \n",
    "        gaia_apogee_dir, fig_dir, force_splines=False, make_spline_plots='both',\n",
    "        n_spline_plots=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
