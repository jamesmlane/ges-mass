{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - calculate_derived_quantities.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges-mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Calculate quantities derived from the best-fits to the data using each \n",
    "model. \n",
    "- The alt/az of the principal axis of the density ellipsoid.\n",
    "- The triaxiality parameter for the density ellipsoid.\n",
    "- fdisk in terms of fractional density to fdisk in terms of fractional number \n",
    "    of stars.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "# Basic\n",
    "import os, sys, pdb, copy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib and plotting \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "from ges_mass import mass as pmass\n",
    "from ges_mass import densprofiles as pdens\n",
    "from ges_mass import util as putil\n",
    "from ges_mass import plot as pplot\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Keywords, Pathing, Loading, Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/keywords_pathing_loading_data_prep.py\n",
    "## Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['BASE_DIR','APOGEE_DR','APOGEE_RESULTS_VERS','GAIA_DR','NDMOD',\n",
    "            'DMOD_MIN','DMOD_MAX','LOGG_MIN','LOGG_MAX','FEH_MIN','FEH_MAX',\n",
    "            'FEH_MIN_GSE','FEH_MAX_GSE','DF_VERSION','KSF_VERSION','NPROCS',\n",
    "            'RO','VO','ZO']\n",
    "base_dir,apogee_dr,apogee_results_vers,gaia_dr,ndmod,dmod_min,dmod_max,\\\n",
    "    logg_min,logg_max,feh_min,feh_max,feh_min_gse,feh_max_gse,df_version,\\\n",
    "    ksf_version,nprocs,ro,vo,zo = putil.parse_config_dict(cdict,keywords)\n",
    "logg_range = [logg_min,logg_max]\n",
    "feh_range = [feh_min,feh_max]\n",
    "feh_range_gse = [feh_min_gse,feh_max_gse]\n",
    "feh_range_all = [feh_min,feh_max_gse]\n",
    "# feh_range_fit = copy.deepcopy( # Need to choose here\n",
    "\n",
    "\n",
    "## Pathing\n",
    "fit_paths = putil.prepare_paths(base_dir,apogee_dr,apogee_results_vers,gaia_dr,\n",
    "                                df_version,ksf_version)\n",
    "data_dir,version_dir,ga_dir,gap_dir,df_dir,ksf_dir,fit_dir = fit_paths\n",
    "\n",
    "## Filenames\n",
    "fit_filenames = putil.prepare_filenames(ga_dir,gap_dir,feh_range_gse)\n",
    "apogee_SF_filename,apogee_effSF_filename,apogee_effSF_mask_filename,\\\n",
    "    iso_grid_filename,clean_kinematics_filename = fit_filenames\n",
    "\n",
    "## File loading and data preparation\n",
    "fit_stuff,other_stuff = putil.prepare_fitting(fit_filenames,\n",
    "    [ndmod,dmod_min,dmod_max], ro,zo,return_other=True)\n",
    "apogee_effSF_mask,dmap,iso_grid,jkmins,dmods,ds,effsel_grid,apof,\\\n",
    "    allstar_nomask,orbs_nomask = fit_stuff\n",
    "Rgrid,phigrid,zgrid = effsel_grid\n",
    "\n",
    "# ## Load the distribution functions\n",
    "# df_filename = df_dir+'dfs.pkl'\n",
    "# betas = [0.3,0.8]\n",
    "# dfs = putil.load_distribution_functions(df_filename, betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = './fig/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/global_fitting_params.py\n",
    "## general kwargs\n",
    "verbose = True\n",
    "\n",
    "## HaloFit kwargs (ordering follows HaloFit.__init__)\n",
    "# allstar and orbs loaded in prep cell\n",
    "init = None\n",
    "init_type = 'ML'\n",
    "# fit_type provided at runtime\n",
    "mask_disk = True\n",
    "mask_halo = True\n",
    "# densfunc, selec provided at runtime\n",
    "# effsel, effsel_grid, effsel_mask, dmods loaded in prep cell\n",
    "nwalkers = 100\n",
    "nit = int(2e3)\n",
    "ncut = int(1e3)\n",
    "# usr_log_prior provided at runtime\n",
    "n_mass = 5000 # int(nwalkers*(nit-ncut))\n",
    "int_r_range = [2.,70.]\n",
    "iso = None # Will read from iso_grid_filename\n",
    "# iso_filename, jkmins loaded in prep cell\n",
    "# feh_range provided at runtime\n",
    "# logg_range loaded in config cell\n",
    "# fit_dir, gap_dir, ksf_dir loaded in prep cell\n",
    "# version provided at runtime\n",
    "# ro, vo, zo loaded in config cell\n",
    "\n",
    "hf_kwargs = {## HaloFit parameters\n",
    "             'allstar':allstar_nomask,\n",
    "             'orbs':orbs_nomask,\n",
    "             'init':init,\n",
    "             'init_type':init_type,\n",
    "             # 'fit_type':fit_type, # provided at runtime\n",
    "             'mask_disk':mask_disk,\n",
    "             'mask_halo':mask_halo,\n",
    "             ## _HaloFit parameters\n",
    "             # 'densfunc':densfunc, # provided at runtime\n",
    "             # 'selec':selec, # provided at runtime\n",
    "             'effsel':apof,\n",
    "             'effsel_mask':apogee_effSF_mask,\n",
    "             'effsel_grid':effsel_grid,\n",
    "             'dmods':dmods,\n",
    "             'nwalkers':nwalkers,\n",
    "             'nit':nit,\n",
    "             'ncut':ncut,\n",
    "             # 'usr_log_prior':usr_log_prior, # provided at runtime\n",
    "             'n_mass':n_mass,\n",
    "             'int_r_range':int_r_range,\n",
    "             'iso':iso,\n",
    "             'iso_filename':iso_grid_filename,\n",
    "             'jkmins':jkmins,\n",
    "             # 'feh_range':feh_range, # provided at runtime\n",
    "             'logg_range':logg_range,\n",
    "             'fit_dir':fit_dir,\n",
    "             'gap_dir':gap_dir,\n",
    "             'ksf_dir':ksf_dir,\n",
    "             # 'version':version, # provided at runtime\n",
    "             'verbose':verbose,\n",
    "             'ro':ro,\n",
    "             'vo':vo,\n",
    "             'zo':zo}\n",
    "\n",
    "## pmass.fit() function kwargs\n",
    "# nprocs set in config file\n",
    "force_fit = True\n",
    "mle_init = True\n",
    "just_mle = False\n",
    "return_walkers = True\n",
    "optimizer_method = 'Powell'\n",
    "mass_int_type = 'spherical_grid'\n",
    "batch_masses = True\n",
    "make_ml_aic_bic = True\n",
    "calculate_masses = True\n",
    "post_optimization = True\n",
    "mcmc_diagnostic = True\n",
    "\n",
    "fit_kwargs = {# 'nprocs':nprocs, # Normally given at runtime \n",
    "              'force_fit':force_fit,\n",
    "              'mle_init':mle_init,\n",
    "              'just_mle':just_mle,\n",
    "              'return_walkers':return_walkers,\n",
    "              'optimizer_method':optimizer_method,\n",
    "              'mass_int_type':mass_int_type,\n",
    "              'batch_masses':batch_masses,\n",
    "              'make_ml_aic_bic':make_ml_aic_bic,\n",
    "              'calculate_masses':calculate_masses,\n",
    "              'post_optimization':post_optimization,\n",
    "              'mcmc_diagnostic':mcmc_diagnostic,\n",
    "              }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_principal_axis_altaz(hf,params=None,degrees=True,n=100):\n",
    "    '''calculate_principal_axis_altaz:\n",
    "    \n",
    "    For a given model calculate the alt/az of the major axis.\n",
    "    \n",
    "    Args:\n",
    "        hf (HaloFit): The HaloFit object.\n",
    "        params (array): The parameters of the model. If None then use all\n",
    "            the parameters from the HaloFit object.\n",
    "        degrees (bool): If True then return alt/az in degrees.\n",
    "        n (int): The number of sets of params to use to calculate the alt/az.\n",
    "    \n",
    "    Returns:\n",
    "        alt (float): The altitude of the major axis.\n",
    "        az (float): The azimuth of the major axis.\n",
    "        '''\n",
    "    if not hf._hasResults:\n",
    "        hf.get_results()\n",
    "    if params is None:\n",
    "        params = hf.samples\n",
    "    params = np.atleast_2d(params)\n",
    "    nparams = params.shape[0]\n",
    "    indx = np.random.choice(nparams,n,replace=False)\n",
    "    alt = np.zeros(n)\n",
    "    az = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        pavec = hf.get_rotated_coords_in_gc_frame(params=params[indx[i]],\n",
    "            vec=np.array([1,0,0]))[0]\n",
    "        # pavec = pavec/np.linalg.norm(pavec)\n",
    "        alt[i],az[i] = putil.vec_to_alt_az(pavec,degrees=degrees)\n",
    "    \n",
    "    return alt,az\n",
    "\n",
    "def calculate_triaxiality_parameter(hf,params=None,n=None):\n",
    "    '''calculate_triaxiality_parameter:\n",
    "\n",
    "    Calculate the triaxiality parameter \n",
    "\n",
    "    Args:\n",
    "        b (float) - ratio of Y to X axes (p in the paper)\n",
    "        c (float) - ratio of Z to X axes (q in the paper\n",
    "\n",
    "    Returns:\n",
    "        T = triaxiality parameter\n",
    "    '''\n",
    "    if not hf._hasResults:\n",
    "        hf.get_results()\n",
    "    if params is None:\n",
    "        params = hf.samples\n",
    "    else:\n",
    "        params = np.atleast_2d(params)\n",
    "    if n is None:\n",
    "        n = params.shape[0]\n",
    "    p_indx,q_indx = pdens.get_densfunc_params_indx(hf.densfunc,['p','q'])\n",
    "    nparams = params.shape[0]\n",
    "    indx = np.random.choice(nparams,n,replace=False)\n",
    "    ps = params[indx,p_indx]\n",
    "    qs = params[indx,q_indx]\n",
    "    abc_vec = np.array([np.ones_like(ps),ps,qs])\n",
    "    c,b,a = np.sort(abc_vec,axis=0)\n",
    "    return (1-(b/a)**2)/(1-(c/a)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate masses within 55 kpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mass = int(1e4)\n",
    "r_min = 2.\n",
    "r_max = [55.,]\n",
    "\n",
    "selecs = ['eLz','AD','JRLz',None]\n",
    "densfuncs = [pdens.triaxial_single_angle_zvecpa,\n",
    "             pdens.triaxial_single_angle_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_single_cutoff_zvecpa,\n",
    "             pdens.triaxial_single_cutoff_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_broken_angle_zvecpa,\n",
    "             pdens.triaxial_broken_angle_zvecpa_plusexpdisk,\n",
    "            #]\n",
    "             pdens.triaxial_double_broken_angle_zvecpa,\n",
    "             pdens.triaxial_double_broken_angle_zvecpa_plusexpdisk]\n",
    "fit_types = ['gse','gse','gse','all']\n",
    "versions = 4*['100w_1e4n']\n",
    "hf_kwargs['verbose'] = True\n",
    "\n",
    "for i,_selec in enumerate(selecs):\n",
    "    print('\\n',_selec,'\\n----')\n",
    "    for j,_densfunc in enumerate(densfuncs):\n",
    "        print('\\n',_densfunc.__name__,'\\n----')\n",
    "        if fit_types[i] == 'gse':\n",
    "            _feh_range = copy.deepcopy(feh_range_gse)\n",
    "        elif fit_types[i] == 'all':\n",
    "            _feh_range = copy.deepcopy(feh_range_all)\n",
    "        hf = pmass.HaloFit(densfunc=_densfunc,\n",
    "                           selec=_selec,\n",
    "                           fit_type=fit_types[i],\n",
    "                           feh_range=_feh_range,\n",
    "                           version=versions[i],\n",
    "                           **hf_kwargs)\n",
    "        hf.get_results()\n",
    "        out = pmass.mass(hf,n_mass=n_mass,int_r_range=[r_min,r_max[0]],\n",
    "                         nprocs=10)\n",
    "        masses = out[0]\n",
    "        if 'plusexpdisk' in _densfunc.__name__:\n",
    "            masses = masses[0]\n",
    "        mlow,mmed,mhigh = np.percentile(masses,[16,50,84])\n",
    "        logmlow,logmmed,logmhigh = np.log10([mlow,mmed,mhigh])\n",
    "        print('mass = {:.2f} +{:.2f} -{:.2f}'.format(mmed,mhigh-mmed,mmed-mlow))\n",
    "        print('log10(mass) = {:.2f} +{:.2f} -{:.2f}'.format(logmmed,logmhigh-logmmed,logmmed-logmlow))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mass fraction within the break radius for the best AD and Halo models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mass = int(1e4)\n",
    "r_min = 2.\n",
    "\n",
    "lb_densfunc = pdens.triaxial_single_angle_zvecpa_plusexpdisk\n",
    "hb_densfunc = pdens.triaxial_broken_angle_zvecpa\n",
    "r_cutoff_ind = pdens.get_densfunc_params_indx(hb_densfunc,['r1'])[0]\n",
    "version = '100w_1e4n'\n",
    "\n",
    "lb_hf = pmass.HaloFit(densfunc=lb_densfunc, \n",
    "                      selec=None,\n",
    "                      fit_type='all',\n",
    "                      feh_range=feh_range_all,\n",
    "                      version='100w_1e4n',\n",
    "                      **hf_kwargs)\n",
    "lb_hf.get_results()\n",
    "hb_hf = pmass.HaloFit(densfunc=hb_densfunc,\n",
    "                      selec='AD',\n",
    "                      fit_type='gse',\n",
    "                      feh_range=feh_range_gse,\n",
    "                      version='100w_1e4n',\n",
    "                      **hf_kwargs)\n",
    "hb_hf.get_results()\n",
    "\n",
    "samples_for_mass = np.random.choice(lb_hf.samples.shape[0],n_mass,replace=False)\n",
    "\n",
    "r_cutoffs = hb_hf.samples[samples_for_mass,r_cutoff_ind]\n",
    "lb_mass = np.zeros(n_mass)\n",
    "hb_mass = np.zeros(n_mass)\n",
    "\n",
    "for i in range(n_mass):\n",
    "    lb_hf_samples = np.atleast_2d(lb_hf.samples[samples_for_mass[i]])\n",
    "    hb_hf_samples = np.atleast_2d(hb_hf.samples[samples_for_mass[i]])\n",
    "\n",
    "    assert hb_hf_samples[0,r_cutoff_ind] == r_cutoffs[i]\n",
    "\n",
    "    lb_out = pmass.mass(lb_hf,lb_hf_samples,int_r_range=[2.,r_cutoffs[i]],\n",
    "                            n_mass=1, nprocs=1, verbose=False)\n",
    "    hb_out = pmass.mass(hb_hf,hb_hf_samples,int_r_range=[2.,r_cutoffs[i]],\n",
    "                            n_mass=1, nprocs=1, verbose=False)\n",
    "    \n",
    "    if 'plusexpdisk' in lb_densfunc.__name__:\n",
    "        lb_mass[i] = lb_out[0][0][0]\n",
    "    else:\n",
    "        lb_mass[i] = lb_out[0][0]\n",
    "    if 'plusexpdisk' in hb_densfunc.__name__:\n",
    "        hb_mass[i] = hb_out[0][0][0]\n",
    "    else:\n",
    "        hb_mass[i] = hb_out[0][0]\n",
    "\n",
    "    print('Calculated mass for sample {}/{}'.format(i+1,n_mass),end='\\r')\n",
    "    \n",
    "mfm,mfl,mfh = np.percentile(hb_mass/lb_mass,[50,16,84])\n",
    "print('\\nMass fraction for hb/lb: {:.2f} +{:.2f} -{:.2f}'.format(mfm,mfh-mfm,mfm-mfl))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate alt-az for all GS/E models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densfuncs = [pdens.triaxial_single_angle_zvecpa,\n",
    "             pdens.triaxial_single_angle_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_single_cutoff_zvecpa,\n",
    "             pdens.triaxial_single_cutoff_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_broken_angle_zvecpa,\n",
    "             pdens.triaxial_broken_angle_zvecpa_plusexpdisk,\n",
    "            #]\n",
    "             pdens.triaxial_double_broken_angle_zvecpa,\n",
    "             pdens.triaxial_double_broken_angle_zvecpa_plusexpdisk]\n",
    "selecs = ['eLz','AD','JRLz']\n",
    "version = '100w_1e4n'\n",
    "fit_type = 'gse'\n",
    "feh_range_fit = copy.deepcopy(feh_range_gse)\n",
    "\n",
    "for i in range(len(selecs)):\n",
    "    for j in range(len(densfuncs)):\n",
    "        hf = pmass.HaloFit(densfunc=densfuncs[j], fit_type=fit_type,\n",
    "            version=version, selec=selecs[i], feh_range=feh_range_fit, \n",
    "            **hf_kwargs)\n",
    "        alt,az = calculate_principal_axis_altaz(hf,degrees=True,n=10000)\n",
    "\n",
    "        alt_low,alt_med,alt_high = np.percentile(alt,[16,50,84])\n",
    "        az_low,az_med,az_high = np.percentile(az,[16,50,84])\n",
    "        alt_low_err = alt_med-alt_low\n",
    "        alt_high_err = alt_high-alt_med\n",
    "        az_low_err = az_med-az_low\n",
    "        az_high_err = az_high-az_med\n",
    "\n",
    "        phi_indx = pdens.get_densfunc_params_indx(hf.densfunc,['phi'])\n",
    "        phi = pdens.denormalize_parameters(hf.samples,hf.densfunc,\n",
    "            phi_in_degr=True)[:,phi_indx]\n",
    "        phi_low,phi_med,phi_high = np.percentile(phi,[16,50,84])\n",
    "\n",
    "        print('\\n')\n",
    "        print('densfunc: {}'.format(hf.densfunc.__name__))\n",
    "        print('selec: {}'.format(hf.selec))\n",
    "        print('alt: {} +{} -{}'.format(alt_med,alt_high_err,alt_low_err))\n",
    "        print('az: {} +{} -{}'.format(az_med,az_high_err,az_low_err))\n",
    "        print('phi: {} +{} -{}'.format(phi_med,phi_high-phi_med,phi_med-phi_low))\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the triaxiality parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pmass.HaloFit(densfunc=densfuncs[2], fit_type=fit_type,\n",
    "            version=version, selec=selecs[1], feh_range=feh_range_fit, \n",
    "            **hf_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some scratch work on triaxiality stuff\n",
    "# p_indx,q_indx = pdens.get_densfunc_params_indx(hf.densfunc,['p','q'])\n",
    "# hf.get_results()\n",
    "# params = hf.samples\n",
    "# ps,qs = params[:,p_indx],params[:,q_indx]\n",
    "# abc_vec = np.array([np.ones_like(ps),ps,qs])\n",
    "# abc_vec.shape\n",
    "# print(ps)\n",
    "# print(qs)\n",
    "# np.median(ps)\n",
    "# calculate_triaxiality_parameter(hf,[3.,10.,0.54,0.46,1.,1.,1.]) # SHould be ~ 0.89\n",
    "# abc_vec\n",
    "# np.sort(abc_vec,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densfuncs = [pdens.triaxial_single_angle_zvecpa,\n",
    "             pdens.triaxial_single_angle_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_single_cutoff_zvecpa,\n",
    "             pdens.triaxial_single_cutoff_zvecpa_plusexpdisk,\n",
    "             pdens.triaxial_broken_angle_zvecpa,\n",
    "             pdens.triaxial_broken_angle_zvecpa_plusexpdisk,\n",
    "            #]\n",
    "             pdens.triaxial_double_broken_angle_zvecpa,\n",
    "             pdens.triaxial_double_broken_angle_zvecpa_plusexpdisk]\n",
    "selecs = ['eLz','AD','JRLz']\n",
    "version = '100w_1e4n'\n",
    "fit_type = 'gse'\n",
    "feh_range_fit = copy.deepcopy(feh_range_gse)\n",
    "\n",
    "for i in range(len(selecs)):\n",
    "    print('\\nselec: {}'.format(selecs[i]))\n",
    "    print('-----------------')\n",
    "    for j in range(len(densfuncs)):\n",
    "        hf = pmass.HaloFit(densfunc=densfuncs[j], fit_type=fit_type,\n",
    "            version=version, selec=selecs[i], feh_range=feh_range_fit, \n",
    "            **hf_kwargs)\n",
    "        \n",
    "        Ts = calculate_triaxiality_parameter(hf,n=100)\n",
    "        T_low,T_med,T_high = np.percentile(Ts,[16,50,84])\n",
    "        T_low_err = T_med-T_low\n",
    "        T_high_err = T_high-T_med\n",
    "        #print('\\n')\n",
    "        print('densfunc: {}'.format(hf.densfunc.__name__))\n",
    "        print('selec: {}'.format(hf.selec))\n",
    "        print('T: {:.3f} +{:.3f} -{:.3f}'.format(T_med,T_high_err,T_low_err))\n",
    "        print('\\n')\n",
    "        #print('\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate fdisk in terms of number of contaminating stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecs = ['eLz','AD','JRLz',None]\n",
    "densfuncs = pdens._densfuncs\n",
    "fit_types = ['gse','gse','gse','all']\n",
    "versions = 4*['100w_1e4n']\n",
    "hf_kwargs['verbose'] = True\n",
    "\n",
    "for i,_selec in enumerate(selecs):\n",
    "    print('\\n',_selec,'\\n----')\n",
    "    for j,_densfunc in enumerate(densfuncs):\n",
    "        if 'plusexpdisk' not in _densfunc.__name__: continue\n",
    "        print('\\n',_densfunc.__name__,'\\n----')\n",
    "        if fit_types[i] == 'gse':\n",
    "            _feh_range = copy.deepcopy(feh_range_gse)\n",
    "        elif fit_types[i] == 'all':\n",
    "            _feh_range = copy.deepcopy(feh_range_all)\n",
    "        hf = pmass.HaloFit(densfunc=_densfunc,\n",
    "                           selec=_selec,\n",
    "                           fit_type=fit_types[i],\n",
    "                           feh_range=_feh_range,\n",
    "                           version=versions[i],\n",
    "                           **hf_kwargs)\n",
    "        hf.get_results()\n",
    "        nh,nd = pmass.fdisk_to_number_of_stars(hf)\n",
    "        fn = nd/(nh+nd)\n",
    "        fdl,fdm,fdh = np.percentile(hf.samples[:,-1],[16,50,84])\n",
    "        fnl,fnm,fnh = np.percentile(fn,[16,50,84])\n",
    "        print('f_d = {:.2f} +{:.2f} -{:.2f}'.format(fdm,fdh-fdm,fdm-fdl))\n",
    "        print('f_n = {:.2f} +{:.2f} -{:.2f}'.format(fnm,fnh-fnm,fnm-fnl))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c09f9892750024efe5c64805177155c0b3b90c2cacf15a9f18cf8d6a11608de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
