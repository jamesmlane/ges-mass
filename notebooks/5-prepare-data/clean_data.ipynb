{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - clean_data.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges-mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Clean the Gaia & APOGEE data and calculate kinematic quantities. Then \n",
    "plot and mask based on abundances / kinematics.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np, pdb, sys, os, dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as apu\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## galpy\n",
    "from galpy import orbit\n",
    "from galpy import potential\n",
    "from galpy import actionAngle as aA\n",
    "\n",
    "sys.path.append('../../src/')\n",
    "from ges_mass import util as putil\n",
    "from ges_mass import ssf as pssf\n",
    "from ges_mass import plot as pplot\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords, Pathing, Loading, Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/keywords_pathing_loading_data_prep.py\n",
    "## Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['BASE_DIR','APOGEE_DR','APOGEE_RESULTS_VERS','GAIA_DR','NDMOD',\n",
    "            'DMOD_MIN','DMOD_MAX','LOGG_MIN','LOGG_MAX','FEH_MIN','FEH_MAX',\n",
    "            'FEH_MIN_GSE','FEH_MAX_GSE','DF_VERSION','KSF_VERSION','NPROCS',\n",
    "            'RO','VO','ZO']\n",
    "base_dir,apogee_dr,apogee_results_vers,gaia_dr,ndmod,dmod_min,dmod_max,\\\n",
    "    logg_min,logg_max,feh_min,feh_max,feh_min_gse,feh_max_gse,df_version,\\\n",
    "    ksf_version,nprocs,ro,vo,zo = putil.parse_config_dict(cdict,keywords)\n",
    "logg_range = [logg_min,logg_max]\n",
    "feh_range = [feh_min,feh_max]\n",
    "feh_range_gse = [feh_min_gse,feh_max_gse]\n",
    "feh_range_all = [feh_min,feh_max_gse]\n",
    "# feh_range_fit = copy.deepcopy( # Need to choose here\n",
    "\n",
    "\n",
    "## Pathing\n",
    "fit_paths = putil.prepare_paths(base_dir,apogee_dr,apogee_results_vers,gaia_dr,\n",
    "                                df_version,ksf_version)\n",
    "data_dir,version_dir,ga_dir,gap_dir,df_dir,ksf_dir,fit_dir = fit_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Potential and action angle object\n",
    "mwpot = potential.MWPotential2014\n",
    "potential.turn_physical_on(mwpot,ro=ro,vo=vo)\n",
    "phi0 = potential.evaluatePotentials(mwpot,1e10,0).value\n",
    "aAS = aA.actionAngleStaeckel(pot=mwpot, delta=0.4, ro=ro, vo=vo, zo=zo, c=True)\n",
    "\n",
    "## Decide how to sample 6D kinematics / calculate kinematic quantities\n",
    "sample_kinematics = True\n",
    "force_sampling = False # Force re-sampling even if file exists\n",
    "save_kinematic_samples = True\n",
    "force_kinematics = False # Force re-calculation even if file exists\n",
    "if sample_kinematics:\n",
    "    n_samples = 100\n",
    "    input_kinematics_filename = gap_dir+'input_kinematics_sampled.npy'\n",
    "    input_kinematics_samples_filename = gap_dir+'_input_kinematics_raw_samples.npy'\n",
    "    sampled_obs_filename = gap_dir+'sampled_obs.npy'\n",
    "    sampled_obs_psd_mask_filename = gap_dir+'sampled_obs_psd_mask.npy'\n",
    "else:\n",
    "    input_kinematics_filename = gap_dir+'input_kinematics_no_sample.npy'\n",
    "    vxvv_no_sample_filename = gap_dir+'vxvv_no_sample.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load APOGEE data\n",
    "allstar_filename = ga_dir+'apogee_allstar.npy'\n",
    "print('APOGEE data release is: '+apogee_dr+', and results version is: '+apogee_results_vers)\n",
    "print('Loading APOGEE from '+allstar_filename)\n",
    "allstar = np.load(allstar_filename)\n",
    "print(str(len(allstar))+' stars in total sample.')\n",
    "\n",
    "# load APOGEE statistical sample index\n",
    "apogee_stat_indx_filename = ga_dir+'apogee_statIndx.npy'\n",
    "print('\\nLoading APOGEE DR16 statistical sample from '+apogee_stat_indx_filename)\n",
    "apogee_stat_indx = np.load(apogee_stat_indx_filename)\n",
    "print(str(np.sum(apogee_stat_indx))+' stars in statistical sample.')\n",
    "\n",
    "# Gaia data and Gaia-APOGEE match index\n",
    "gaia_data_filename = ga_dir+'gaia_data.npy'\n",
    "gaia_apogee_matches_filename = ga_dir+'gaia_apogee_matches.npy'\n",
    "print('\\nGaia data release is: '+gaia_dr)\n",
    "print('Loading Gaia catalog from '+gaia_data_filename)\n",
    "gaia_data = np.load(gaia_data_filename, allow_pickle=True)\n",
    "print('Loading Gaia-APOGEE matches from '+gaia_apogee_matches_filename)\n",
    "gaia_apogee_matches_indx = np.load(gaia_apogee_matches_filename)\n",
    "\n",
    "# Apply the statistical sample index and Gaia-APOGEE matching index\n",
    "allstar_gaia = allstar[apogee_stat_indx][gaia_apogee_matches_indx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean data\n",
    "apply:\n",
    "- data finiteness cuts\n",
    "- quality cuts (distance error, logg error)\n",
    "- remove bulge\n",
    "- remove GCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have defined 6D kinematics for eccentricities\n",
    "omask_finite = np.isfinite(gaia_data['RA']) &\\\n",
    "               np.isfinite(gaia_data['DEC']) &\\\n",
    "               np.isfinite(gaia_data['pmra']) &\\\n",
    "               np.isfinite(gaia_data['pmdec']) &\\\n",
    "               np.isfinite(allstar_gaia['weighted_dist']) &\\\n",
    "               np.isfinite(allstar_gaia['VHELIO_AVG'])\n",
    "\n",
    "# Cut high fractional distance uncertainty, undefined eccentricity, \n",
    "# undefined Fe/H, undefined Al/Fe, high log(g) uncertainty\n",
    "omask_quality = ((allstar_gaia['weighted_dist_error']/\\\n",
    "                  allstar_gaia['weighted_dist'] < 0.2) &\\\n",
    "                 # (allstar_gaia['MG_FE'] > -9999) &\\\n",
    "                 (allstar_gaia['FE_H'] > -9999) &\\\n",
    "                 (allstar_gaia['AL_FE'] > -9999) &\\\n",
    "                 (allstar_gaia['LOGG_ERR'] < 0.1)\n",
    "                )\n",
    "omask_quality2 = ((allstar_gaia['weighted_dist_error']/\\\n",
    "                  allstar_gaia['weighted_dist'] < 0.2) &\\\n",
    "                 # (allstar_gaia['MG_FE'] > -9999) &\\\n",
    "                 (allstar_gaia['FE_H'] > -9999) &\\\n",
    "                 (allstar_gaia['AL_FE'] > -9999)#  &\\\n",
    "                 # (allstar_gaia['LOGG_ERR'] < 0.1)\n",
    "                )\n",
    "\n",
    "# Cut bulge fields. Within 20 degrees of the galactic center\n",
    "omask_bulge = ~(((allstar_gaia['GLON'] > 340.) |\\\n",
    "                 (allstar_gaia['GLON'] < 20.)) &\\\n",
    "                (np.fabs(allstar_gaia['GLAT']) < 20.)\n",
    "               )\n",
    "\n",
    "# Remove globular cluster fields. See corresponding notebook\n",
    "gc_locids = pssf.get_globular_cluster_fields()\n",
    "omask_gc = ~np.isin(allstar_gaia['LOCATION_ID'],gc_locids)\n",
    "\n",
    "omask = omask_finite & omask_quality & omask_bulge & omask_gc\n",
    "\n",
    "allstar_input = allstar_gaia[omask]\n",
    "gaia_input = gaia_data[omask]\n",
    "print(str(np.sum(omask))+' sources after masking')\n",
    "\n",
    "# Make orbits\n",
    "vxvv_input = np.array([gaia_input['ra'],\n",
    "                       gaia_input['dec'],\n",
    "                       allstar_input['weighted_dist']/1e3,\n",
    "                       gaia_input['pmra'],\n",
    "                       gaia_input['pmdec'],\n",
    "                       allstar_input['VHELIO_AVG']\n",
    "                      ]).T\n",
    "orbs_input = orbit.Orbit(vxvv_input, radec=True, ro=ro, vo=vo, zo=zo)\n",
    "\n",
    "# Sanity\n",
    "assert np.all(orbs_input.ra().to(apu.deg).value-gaia_input['ra']<1e-8)\n",
    "assert np.all(orbs_input.dec().to(apu.deg).value-gaia_input['dec']<1e-8)\n",
    "assert np.all(orbs_input.pmra().to(apu.mas/apu.yr).value-gaia_input['pmra']<1e-8)\n",
    "assert np.all(orbs_input.pmdec().to(apu.mas/apu.yr).value-gaia_input['pmdec']<1e-8)\n",
    "assert np.all(orbs_input.dist().to(apu.pc).value-allstar_input['weighted_dist']<1e-8)\n",
    "assert np.all(orbs_input.vlos().to(apu.km/apu.s).value-allstar_input['VHELIO_AVG']<1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allstar_gaia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(gaia_data['pmdec'][~omask_finite & omask_quality & omask_bulge & omask_gc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(omask_finite & omask_quality & ~omask_bulge & omask_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omask2 = (omask_finite & omask_quality2 & omask_bulge & omask_gc)\n",
    "logg_mask = (allstar_gaia['LOGG'] > 1) & (allstar_gaia['LOGG'] < 3)\n",
    "\n",
    "print(np.sum(omask2))\n",
    "print(np.sum(omask)/np.sum(omask2))\n",
    "print(np.sum(omask & logg_mask))\n",
    "print(np.sum(omask2 & logg_mask))\n",
    "print(np.sum(omask & logg_mask)/np.sum(omask2 & logg_mask))\n",
    "print(np.sum(omask2 & logg_mask)/np.sum(omask & logg_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(allstar_input['weighted_dist']/1000., allstar_input['old_weighted_dist']/1000., \n",
    "#            s=1., alpha=0.1, color='Black', zorder=2)\n",
    "# ax.plot([0.,100.], [0.,100.], color='Red', linestyle='dashed', zorder=3)\n",
    "# ax.set_xlabel('AstroNN distance DR16 [kpc]')\n",
    "# ax.set_ylabel('AstroNN distance DR14 [kpc]')\n",
    "# ax.set_xlim(0,100)\n",
    "# ax.set_ylim(0,100)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(orbs_input.dist().to(apu.kpc).value, 1./gaia_input['parallax'], \n",
    "#            s=1., alpha=0.1, color='Black', zorder=2)\n",
    "# ax.plot([0.,100.], [0.,100.], color='Red', linestyle='dashed', zorder=3)\n",
    "# ax.set_xlabel('AstroNN distance [kpc]')\n",
    "# ax.set_ylabel('Inverted Gaia parallax [kpc]')\n",
    "# ax.set_xlim(0,100)\n",
    "# ax.set_ylim(0,100)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do MC sampling of kinematic parameters\n",
    "\n",
    "if sample_kinematics and \\\n",
    "    (not os.path.exists(sampled_obs_filename) or force_sampling):\n",
    "    # Observables\n",
    "    ra = gaia_input['ra']\n",
    "    dec = gaia_input['dec']\n",
    "    dist = allstar_input['weighted_dist']/1e3\n",
    "    pmra = gaia_input['pmra']\n",
    "    pmdec = gaia_input['pmdec']\n",
    "    RV = allstar_input['VHELIO_AVG']\n",
    "\n",
    "    # Errors\n",
    "    ra_e = gaia_input['ra_error']\n",
    "    dec_e = gaia_input['dec_error']\n",
    "    dist_e = allstar_input['weighted_dist_error']/1e3\n",
    "    pmra_e = gaia_input['pmra_error']\n",
    "    pmdec_e = gaia_input['pmdec_error']\n",
    "    RV_e = allstar_input['VERR']\n",
    "\n",
    "    # Correlations, if using AstroNN then set distance correlations to 0.\n",
    "    radec = gaia_input['ra_dec_corr']\n",
    "    radist = 0.\n",
    "    rapmra = gaia_input['ra_pmra_corr']\n",
    "    rapmdec = gaia_input['ra_pmdec_corr']\n",
    "    decdist = 0.\n",
    "    decpmra = gaia_input['dec_pmra_corr']\n",
    "    decpmdec = gaia_input['dec_pmdec_corr']\n",
    "    distpmra = 0.\n",
    "    distpmdec = 0.\n",
    "    pmrapmdec = gaia_input['pmra_pmdec_corr']\n",
    "\n",
    "    # Covariance matrix for observables, hardcode RV covariance to be 0.\n",
    "    zarr = np.zeros(len(allstar_input))\n",
    "    cov = np.zeros([len(allstar_input),6,6])\n",
    "    cov[:,0] = np.dstack([ra_e**2, ra_e*dec_e*radec, ra_e*dist_e*radist, \n",
    "                          ra_e*pmra_e*rapmra, ra_e*dec_e*rapmdec, zarr])[0]\n",
    "    cov[:,1,1:] = np.dstack([dec_e**2, dec_e*dist_e*decdist, dec_e*pmra_e*decpmra, \n",
    "                             dec_e*pmdec_e*decpmdec, zarr])[0]\n",
    "    cov[:,2,2:] = np.dstack([dist_e**2, dist_e*pmra_e*distpmra, \n",
    "                             dist_e*pmdec_e*distpmdec, zarr])[0]\n",
    "    cov[:,3,3:] = np.dstack([pmra_e**2, pmra_e*pmdec_e*pmrapmdec, zarr])[0]\n",
    "    cov[:,4,4:] = np.dstack([pmdec_e**2, zarr])[0]\n",
    "    cov[:,5,5] = RV_e**2\n",
    "    # Symmetric:\n",
    "    cov[:,:,0] = cov[:,0]\n",
    "    cov[:,1:,1] = cov[:,1,1:]\n",
    "    cov[:,2:,2] = cov[:,2,2:]\n",
    "    cov[:,3:,3] = cov[:,3,3:]\n",
    "    cov[:,4:,4] = cov[:,4,4:]\n",
    "\n",
    "    # Means\n",
    "    mean = np.dstack([ra,dec,dist,pmra,pmdec,RV])[0]\n",
    "\n",
    "    assert np.all(np.isfinite(mean)), 'Non-finite elements in mean array'\n",
    "    assert np.all(np.isfinite(cov)), 'Non-finite elements in covariance array'\n",
    "\n",
    "    # Mask for positive-semidefiniteness (required for multivariate normal sampling)\n",
    "    omask_psd = np.ones((len(allstar_input)),dtype=bool)\n",
    "\n",
    "    # Samples\n",
    "    sampled_obs = np.empty((len(allstar_input),n_samples,6))\n",
    "    for i in tqdm(range(len(allstar_input))):\n",
    "        try:\n",
    "            sampled_obs[i] = np.random.multivariate_normal(mean[i], cov[i],\n",
    "                                                           n_samples, \n",
    "                                                           check_valid='raise')\n",
    "        except ValueError:\n",
    "            print('Sampling failed on star i='+str(i))\n",
    "            omask_psd[i] = False\n",
    "    \n",
    "    # Save the samples\n",
    "    print('Saving sampled kinematics to '+sampled_obs_filename)\n",
    "    np.save(sampled_obs_filename,sampled_obs,allow_pickle=True)\n",
    "    np.save(sampled_obs_psd_mask_filename,omask_psd,allow_pickle=True)\n",
    "elif sample_kinematics and os.path.exists(sampled_obs_filename):\n",
    "    print('Loading sampled kinematics from '+sampled_obs_filename)\n",
    "    sampled_obs = np.load(sampled_obs_filename,allow_pickle=True)\n",
    "    omask_psd = np.load(sampled_obs_psd_mask_filename,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# i=5\n",
    "# off = (np.median(sampled_obs[omask_psd,:,i],axis=1) - mean[omask_psd,i]) /\\\n",
    "#     np.abs(mean[omask_psd,i])\n",
    "# off_lim = 1e-3\n",
    "# ax.hist(off,bins=50,range=(-off_lim,off_lim))\n",
    "# ax.axvline(0.,color='Black')\n",
    "# fig.show()\n",
    "\n",
    "# print(str(np.sum(np.abs(off)<off_lim))+'/'+str(len(off)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate kinematic parameters\n",
    "\n",
    "if force_kinematics or not os.path.exists(input_kinematics_filename):\n",
    "    \n",
    "    deltas_input = np.zeros((len(allstar_input)))\n",
    "    eELzs_input = np.zeros((3,len(allstar_input)))\n",
    "    accs_input = np.zeros((3,len(allstar_input)))\n",
    "    orbextr_input = np.zeros((3,len(allstar_input)))\n",
    "    \n",
    "    if save_kinematic_samples:\n",
    "        _deltas_input_nomed = np.zeros((len(allstar_input),n_samples))\n",
    "        _eELzs_input_nomed = np.zeros((3,len(allstar_input),n_samples))\n",
    "        _accs_input_nomed = np.zeros((3,len(allstar_input),n_samples))\n",
    "        _orbextr_input_nomed = np.zeros((3,len(allstar_input),n_samples))\n",
    "    \n",
    "    if sample_kinematics:\n",
    "        print('Calculating kinematics using sampling')\n",
    "        for i in tqdm(range(len(allstar_input))):\n",
    "            if not omask_psd[i]: continue\n",
    "\n",
    "            _orbs = orbit.Orbit(sampled_obs[i,:,:], radec=True, ro=ro, vo=vo, zo=zo)\n",
    "            deltas,eELzs,accs,orbextr = putil.calculate_accs_eELzs_orbextr_Staeckel(\n",
    "                _orbs,mwpot,aAS)\n",
    "            \n",
    "            deltas_input[i] = np.nanmedian(deltas)\n",
    "            eELzs_input[:,i] = np.nanmedian(eELzs,axis=1)\n",
    "            accs_input[:,i] = np.nanmedian(accs,axis=1)\n",
    "            orbextr_input[:,i] = np.nanmedian(orbextr,axis=1)\n",
    "            \n",
    "            if save_kinematic_samples:\n",
    "                _deltas_input_nomed[i,:] = deltas\n",
    "                _eELzs_input_nomed[:,i,:] = eELzs\n",
    "                _accs_input_nomed[:,i,:] = accs\n",
    "                _orbextr_input_nomed[:,i,:] = orbextr\n",
    "    else:\n",
    "        print('Calculating kinematics without sampling')\n",
    "        _vxvv = np.array([gaia_input['ra'],\n",
    "                          gaia_input['dec'],\n",
    "                          allstar_input['weighted_dist']/1e3,\n",
    "                          gaia_input['pmra'],\n",
    "                          gaia_input['pmdec'],\n",
    "                          allstar_input['VHELIO_AVG']\n",
    "                         ]).T\n",
    "        _orbs = orbit.Orbit(_vxvv, radec=True, ro=ro, vo=vo, zo=zo)\n",
    "        deltas_input,eELzs_input,accs_input,orbextr_input = \\\n",
    "            putil.calculate_accs_eELzs_orbextr_Staeckel(_orbs,mwpot,aAS)\n",
    "        np.save(vxvv_no_sample_filename,_vxvv,allow_pickle=True)\n",
    "\n",
    "    print('Saving deltas, eELz, actions, extrema to '+input_kinematics_filename)\n",
    "    with open(input_kinematics_filename,'wb') as f:\n",
    "        pickle.dump([deltas_input,eELzs_input,accs_input,orbextr_input],f)\n",
    "    if save_kinematic_samples:\n",
    "        print('Saving deltas, eELz, actions, extrema samples to '+\\\n",
    "              input_kinematics_samples_filename)\n",
    "        with open(input_kinematics_samples_filename,'wb') as f:\n",
    "            pickle.dump([_deltas_input_nomed,_eELzs_input_nomed,\n",
    "                         _accs_input_nomed,_orbextr_input_nomed],f)\n",
    "else:\n",
    "    print('Loading deltas, eELz, actions, extrema from '+input_kinematics_filename)\n",
    "    with open(input_kinematics_filename,'rb') as f:\n",
    "        deltas_input,eELzs_input,accs_input,orbextr_input = \\\n",
    "            pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply mask based on kinematics\n",
    "- Just on eccentricity\n",
    "- Also on positive-semidefiniteness of covariance matrix if sampling was done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omask_kin = (eELzs_input[0,:] < 1.) &\\\n",
    "            (eELzs_input[0,:] > 0.)\n",
    "\n",
    "omask_final = omask_kin\n",
    "if sample_kinematics:\n",
    "    omask_final &= omask_psd\n",
    "\n",
    "gaia_omask = gaia_input[omask_final]\n",
    "allstar_omask = allstar_input[omask_final]\n",
    "os_omask = orbs_input[omask_final]\n",
    "eELzs_omask = eELzs_input[:,omask_final]\n",
    "accs_omask = accs_input[:,omask_final]\n",
    "orbextr_omask = orbextr_input[:,omask_final]\n",
    "\n",
    "print('Final number of stars: '+str(len(os_omask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_kinematics:\n",
    "    omask_kinematics_filename = gap_dir+'clean_kinematics_sampled.npy'\n",
    "else:\n",
    "    omask_kinematics_filename = gap_dir+'clean_kinematics_no_sample.npy'\n",
    "    \n",
    "with open(omask_kinematics_filename,'wb') as f:\n",
    "    pickle.dump([gaia_omask,allstar_omask,os_omask,eELzs_omask,accs_omask,orbextr_omask],f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this sample only has quality cuts applied, no $\\log g$ cuts yet. This is so that the parameter can be modified without having to re-run the sampling"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "nteract": {
   "version": "0.14.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c09f9892750024efe5c64805177155c0b3b90c2cacf15a9f18cf8d6a11608de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
